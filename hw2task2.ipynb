{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfqrLjvV4PZ0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usyruRUL4R-l",
        "outputId": "2281ab17-f421-4041-dfc0-2476bb1949a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/hw2_aml/task2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rpmQXg_4Vb4",
        "outputId": "4f6d9a90-a640-4ba9-e10f-e5a56c86d47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSW_NB15_testing-set.csv  UNSW_NB15_training-set.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/hw2_aml/task2'"
      ],
      "metadata": {
        "id": "p8o4zqcE41vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv((os.path.join(path,'UNSW_NB15_training-set.csv')))\n",
        "test =pd.read_csv((os.path.join(path,'UNSW_NB15_testing-set.csv')))"
      ],
      "metadata": {
        "id": "BHWNH-h45S5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['label','id'],axis=1,inplace=True)\n",
        "test.drop(['label','id'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "97E3ZAfuWZZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'shape is train csv is {train.shape}')\n",
        "print(f'shape is test csv is {test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGPvxmVP5hs4",
        "outputId": "7fe5add8-3f08-4485-a274-84abbbd002e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape is train csv is (82332, 43)\n",
            "shape is test csv is (175341, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.loc[:, train.columns != 'attack_cat']\n",
        "y_train = train['attack_cat']\n",
        "X_test = test.loc[:, test.columns != 'attack_cat']\n",
        "y_test = test['attack_cat']"
      ],
      "metadata": {
        "id": "clp4zmgVJ_t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catfeats = X_train.select_dtypes(include=['bool','object','datetime64']).columns.tolist()"
      ],
      "metadata": {
        "id": "tBHTpPn05oie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = X_train.columns.tolist()\n",
        "#cols"
      ],
      "metadata": {
        "id": "_m59xLWf8z26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' Number of missing values in training set is {X_train.isnull().sum().sum()}')\n",
        "print(f' Number of missing values in testing set is {X_test.isnull().sum().sum()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93-wXI3G65wq",
        "outputId": "ce4a0a00-569d-4628-998b-01ef1b9754bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of missing values in training set is 0\n",
            " Number of missing values in testing set is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
        "enc.fit(X_train[catfeats])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04QvKJ-16s6f",
        "outputId": "e4a84c10-80d2-413d-e6bb-865403f3679c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc_y = LabelEncoder()\n",
        "enc_y.fit(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfXjfDdWpl1w",
        "outputId": "4ca36ead-3a1f-415d-bbda-4fb8a4a666fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()"
      ],
      "metadata": {
        "id": "AKUmGnBL9fgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_data(df,enc,scaler,feats,cols):\n",
        "    new_feats = enc.transform(df[feats])\n",
        "    new_cols = pd.DataFrame(new_feats, columns=feats,dtype=int)\n",
        "    drop_df = df.drop(feats, axis=1)\n",
        "    df.reset_index()\n",
        "    drop_df.reset_index()\n",
        "    new_cols.reset_index()\n",
        "    new_df = pd.concat([drop_df, new_cols], axis=1)\n",
        "    scaler.fit(new_df)\n",
        "    scaled = scaler.transform(new_df)\n",
        "    final_df = pd.DataFrame(scaled,columns = cols)\n",
        "    #new_df.drop(features_name, axis=1, inplace=True)\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "hJ9DJz2M6ABo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_y(df,enc):\n",
        "  new_feat = enc.transform(df)\n",
        "  df = pd.DataFrame(new_feat)\n",
        "  df.rename(columns = {0:'attack_cat'},inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "ZGrQ7nfKn3XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_train = transform_data(X_train,enc,scaler,catfeats,cols)\n",
        "new_X_test = transform_data(X_test,enc,scaler,catfeats,cols)"
      ],
      "metadata": {
        "id": "FQwwWUR19Rdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of new train is {new_X_train.shape}\")\n",
        "print(f\"Shape of new test is {new_X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPfz5SMs9ZHL",
        "outputId": "23ad8303-e6b5-4dac-d043-dfec8b4c0888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of new train is (82332, 42)\n",
            "Shape of new test is (175341, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_f = transform_y(y_train,enc_y)\n",
        "y_test_f = transform_y(y_test,enc_y)"
      ],
      "metadata": {
        "id": "Vh4W0_JHobJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_useless(df):\n",
        "  useless_cols = []\n",
        "  l = df.columns \n",
        "  count = 0\n",
        "  for i in l:\n",
        "    res = df[i].value_counts(normalize=True)*100\n",
        "  #print(typo)\n",
        "    if any(x >= np.float64(99.0) for x in res.values):\n",
        "      useless_cols.append(i)\n",
        "  new_df = df.drop(useless_cols,axis=1)\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "JAwUfiS-_04q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_f = drop_useless(new_X_train)\n",
        "X_test_f = drop_useless(new_X_test)"
      ],
      "metadata": {
        "id": "nwFZHIzmA601"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of new train is {X_train_f.shape}\")\n",
        "print(f\"Shape of new test is {X_test_f.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwV-a09aC1SK",
        "outputId": "ee951b75-6e30-44f5-afbe-a9b30dceceec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of new train is (82332, 40)\n",
            "Shape of new test is (175341, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the cGAN model"
      ],
      "metadata": {
        "id": "KMQ6_hEMEq-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "6Pwn4j9IE4Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset class was created to use dataloader\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X,Y):\n",
        "\n",
        "        x = X.iloc[:,:].values\n",
        "        y = Y.iloc[:].values\n",
        "        self.x_train = torch.tensor(x,dtype=torch.float32)\n",
        "        self.y_train = torch.tensor(y,dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.x_train)\n",
        "    def __getitem__(self,idx):\n",
        "        X_1 = self.x_train[idx]\n",
        "        y_1 = self.y_train[idx]\n",
        "        return X_1,y_1"
      ],
      "metadata": {
        "id": "gyo1ZFyVmfg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = MyDataset(X_train_f,y_train_f)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=64)"
      ],
      "metadata": {
        "id": "vkxvtxQrmhqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testset = MyDataset(X_test_f,y_test_f)\n",
        "testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=64)"
      ],
      "metadata": {
        "id": "pB9N6f_snhe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im,l = next(iter(trainloader))\n",
        "print(l.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_lhWWqkveoX",
        "outputId": "1ea1fa64-84ab-45ce-e37d-4643bca82aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Available device : {device}\")"
      ],
      "metadata": {
        "id": "B7TTX8vQFzyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e10860c-85de-41d0-99cf-291a21d004e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device : cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## To print layer outputs ########\n",
        "class PrintLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintLayer, self).__init__()\n",
        "                    \n",
        "    def forward(self, x):\n",
        "        # Do your print / debug stuff here\n",
        "        print(x)\n",
        "        return x\n",
        "\n",
        "########################################\n"
      ],
      "metadata": {
        "id": "9TuRbSAecrWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self,output_dim, noise_dim=32):\n",
        "        super(Generator, self).__init__()\n",
        "        input_out_feats = 64\n",
        "        emb_dim = 5\n",
        "        #output_dim = 20 + emb_dim\n",
        "        \n",
        "        self.input_layer = nn.Linear(in_features=noise_dim, out_features=input_out_feats)\n",
        "        self.emb_y = nn.Sequential(nn.Embedding(num_embeddings=10,embedding_dim=emb_dim), nn.Flatten())\n",
        "        self.model = nn.Sequential( nn.Linear(input_out_feats + emb_dim, 128), nn.ReLU(),  # 64 + 5\n",
        "                                    nn.Linear(128, 256), nn.ReLU(),\n",
        "                                    nn.Linear(256, 512), nn.ReLU(),\n",
        "                                    nn.Linear(512, output_dim), nn.Tanh())\n",
        "        \n",
        "    def forward(self, x, y):\n",
        "         x = self.input_layer(x)\n",
        "         y = self.emb_y(y)\n",
        "         return self.model(torch.cat((x, y), dim=1))\n",
        "        \n",
        "        \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        emb_dim = 5\n",
        "        self.emb_y = nn.Sequential(nn.Embedding(num_embeddings=10,embedding_dim=emb_dim),nn.Flatten())\n",
        "        self.model = nn.Sequential(nn.Linear(input_size + emb_dim, 512), nn.LeakyReLU(),\n",
        "                                   nn.Linear(512, 256), nn.LeakyReLU(),\n",
        "                                   nn.Linear(256, 128), nn.LeakyReLU(),\n",
        "                                   nn.Linear(128, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        y = self.emb_y(y)\n",
        "        #print(\"Shape :\", y.shape)\n",
        "        #print(\"shape of x from dis is \", x.shape)\n",
        "        #print(\"shape of cat from dis is \", torch.cat((x, y),dim=1).shape)\n",
        "        return self.model(torch.cat((x, y),dim=1))"
      ],
      "metadata": {
        "id": "rE62L4KnBzf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_noise(BATCH_SIZE, z_noise):\n",
        "    return torch.tensor(np.random.uniform(0., 1., size=[BATCH_SIZE, z_noise]))\n",
        "\n",
        "gen_noise(64,32).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5BPz9kdjRey",
        "outputId": "bd7844b7-d314-455c-f772-42468a02a4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import init\n",
        "def init_weights(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.normal_(m.weight,0,1)\n",
        "        m.bias.data.fill_(1)\n",
        "  elif isinstance(m,nn.BatchNorm1d):\n",
        "        torch.nn.init.normal_(m.weight,0,1)\n",
        "        m.bias.data.zero_()"
      ],
      "metadata": {
        "id": "KFZIYAb-HHb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label-smoothing\n",
        "REAL = 0.9\n",
        "FAKE = 0.1\n",
        "BATCH_SIZE = 64\n",
        "Z_DIM = 32\n",
        "learning_rate = 0.0005\n",
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "EXhx62x7q63i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILD The NETWORK\n",
        "\n",
        "def Build_network(Z_DIM):\n",
        "\n",
        "  D = Discriminator(input_size=40).to(device).float()\n",
        "  G = Generator(output_dim=40, noise_dim=Z_DIM).to(device).float()\n",
        "\n",
        "  D.apply(init_weights)\n",
        "  G.apply(init_weights)\n",
        "\n",
        "  print(\"Generator model is, \", G)\n",
        "  print(\"Discriminator model is \", D)\n",
        "\n",
        "  return D,G"
      ],
      "metadata": {
        "id": "QJMsU7mXIrRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D, G = Build_network(Z_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTmzAyEQrH-x",
        "outputId": "5546b1f3-42c5-440d-e631-9e03a5fc024b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator model is,  Generator(\n",
            "  (input_layer): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (emb_y): Sequential(\n",
            "    (0): Embedding(10, 5)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=69, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=512, out_features=40, bias=True)\n",
            "    (7): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator model is  Discriminator(\n",
            "  (emb_y): Sequential(\n",
            "    (0): Embedding(10, 5)\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=45, out_features=512, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.01)\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): LeakyReLU(negative_slope=0.01)\n",
            "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_module = nn.BCELoss()\n",
        "\n",
        "D_optimizer = optim.SGD(D.parameters(), learning_rate)\n",
        "G_optimizer = optim.SGD(G.parameters(), learning_rate)"
      ],
      "metadata": {
        "id": "3Ax-zNHFsJSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_noise():\n",
        "    return torch.tensor(np.random.uniform(0., 1., size=[BATCH_SIZE, Z_DIM]))\n",
        "\n",
        "def g_training_step(x, y):\n",
        "    # generate the noise\n",
        "    G_optimizer.zero_grad()\n",
        "    z = gen_noise().to(torch.float32).to(device)\n",
        "    y = y.to(device)\n",
        "    # get fake samples from generator\n",
        "    x_fake = G(z, y)\n",
        "    # generate labels for fake data - we are training for the G, so we will lie to the D and say that this is real data\n",
        "    y_fake = torch.tensor([[REAL]] * BATCH_SIZE).to(device)\n",
        "    # get D's verdict\n",
        "    D_verdict = D(x_fake, y)\n",
        "    # calculate loss\n",
        "    G_loss = loss_module(D_verdict, y_fake)\n",
        "    # update the model\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "    return G_loss.item() # \n",
        "\n",
        "def d_training_step(x, y):\n",
        "    # this time we are training the D, so first - we give it real data\n",
        "    D_optimizer.zero_grad()\n",
        "    x_real, y_real = x, torch.tensor([[REAL]] * BATCH_SIZE).to(device)\n",
        "    y = y.to(device)\n",
        "    #print(\"X type\", x_real.dtype)\n",
        "    #print(\"Y type\", y.dtype)\n",
        "    # get its verdict\n",
        "    D_verdict = D(x_real.to(device), y)\n",
        "    # calculate the loss\n",
        "    D_real_loss = loss_module(D_verdict, y_real)\n",
        "\n",
        "    # now we give it the fake data and tell it that it's fake\n",
        "    # for the first few epochs we could tell it that it is actually REAL as well, just to prevent it from learning too fast\n",
        "    z = gen_noise().to(torch.float32).to(device)\n",
        "    x_fake, y_fake = G(z, y), torch.tensor([[FAKE]] * BATCH_SIZE).to(device)\n",
        "    D_verdict = D(x_fake, y)\n",
        "    # update the model\n",
        "    D_fake_loss = loss_module(D_verdict, y_fake)\n",
        "    # its final loss is the sum of two losses\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "    return D_loss.item()"
      ],
      "metadata": {
        "id": "wYAJLIBKJYa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_noise().dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yljcK1KjthEm",
        "outputId": "5d621770-3cfd-46ad-e34d-2563aefbed07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_every = 1\n",
        "def freeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "def unfreeze_model(model):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "def train(n_epochs,dataloader):\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        D_losses, G_losses = [], []\n",
        "        for x,y in dataloader:\n",
        "            # first we train ONLY the D\n",
        "            freeze_model(G), unfreeze_model(D)\n",
        "            d_loss = d_training_step(x, y.int())\n",
        "            D_losses.append(d_loss)\n",
        "            # then we train ONLY the G\n",
        "            freeze_model(D), unfreeze_model(G)\n",
        "            g_loss = g_training_step(x, y.int())\n",
        "            G_losses.append(g_loss)\n",
        "\n",
        "        if epoch % print_every == 0 or epoch == 1 or epoch == n_epochs:\n",
        "            print(f'{epoch}:\\tloss_d: {round(np.mean(D_losses), 4)}\\tloss_g: {round(np.mean(G_losses), 4)}')"
      ],
      "metadata": {
        "id": "M0N7E7jpKNoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(2000,trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "CDckazLBr-Os",
        "outputId": "41184839-b07b-4350-c10e-830abccb1f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-6a085881674b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-184-5268854f2549>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, dataloader)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# first we train ONLY the D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mfreeze_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreeze_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mD_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# then we train ONLY the G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-183-a56ae06c32ce>\u001b[0m in \u001b[0;36md_training_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mD_verdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mD_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_verdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# now we give it the fake data and tell it that it's fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3056\u001b[0m         raise ValueError(\n\u001b[1;32m   3057\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3058\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3059\u001b[0m         )\n\u001b[1;32m   3060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([28, 1])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "UY6MZc4XyKOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MMpwuUofM_Ii",
        "outputId": "4dee4643-3ce5-4c65-9c4c-e006856f6b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport torch\\n\\n# Check for a GPU\\ntrain_on_gpu = torch.cuda.is_available()\\nif not train_on_gpu:\\n    print('No GPU found. Please use a GPU to train your neural network.')\\nelse:\\n    print('Training on GPU!')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explainable Boosting"
      ],
      "metadata": {
        "id": "IBCun_JyyM3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.glassbox import ExplainableBoostingClassifier"
      ],
      "metadata": {
        "id": "bmZZ86-UyP4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm = ExplainableBoostingClassifier(random_state=seed)\n",
        "ebm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HfJYWoTXyWh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predebm = clf.predict(x_test)\n",
        "accuracy_score(y_test, y_predebm)"
      ],
      "metadata": {
        "id": "jqCUZ1xXyYoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Net"
      ],
      "metadata": {
        "id": "BNdRzf1Eyaw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self,inp,H,output):\n",
        "        super(SimpleNN,self).__init__()\n",
        "        self.linear1=nn.Linear(inp,H)\n",
        "        self.linear2=nn.Linear(H,output)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x=self.linear1(x) \n",
        "        x=torch.sigmoid(self.linear2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "5epmJiBCycgR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}